{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f45b4-e29c-4701-b3a3-fb7f65856d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath1 = \"/data/students/bigdata-01QYD/Lab7_DBD/register.csv\"\n",
    "inputPath2 = \"/data/students/bigdata-01QYD/Lab7_DBD/stations.csv\"\n",
    "outputPath = \"/Lab8/Lab8_SQL\" \n",
    "threshold = 0.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082892c-3568-45cc-bc13-83abb831a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF1 = spark.read.load(inputPath1, format=\"csv\", delimiter=\"\\\\t\", header=True, inferSchema=True)\n",
    "inputDF1.createOrReplaceTempView(\"readings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133856cb-2c5d-486f-a98d-06207e015244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullFunction(free_slots):\n",
    "    if free_slots==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "spark.udf.register(\"full\", fullFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e6460-fc4e-4d49-8ed1-826846bd3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedPairsDF = spark.sql(\"SELECT station, date_format(timestamp,'EE') as dayofweek, hour(timestamp) as hour, avg(full(free_slots)) as criticality\\\n",
    "                            FROM readings\\\n",
    "                            WHERE free_slots <> 0 OR used_slots <> 0\\\n",
    "                            GROUP BY station, date_format(timestamp,'EE'), hour(timestamp)\\\n",
    "                            HAVING avg(full(free_slots))>\"+str(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb292ca8-fd53-413b-982d-bff66c82a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedPairsDF.createOrReplaceTempView(\"criticals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259cd59-cd31-469a-bbe8-600c5c44b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF2 = spark.read.load(inputPath2, format=\"csv\",delimiter=\"\\\\t\",header=True,inferSchema=True)\n",
    "inputDF2.createOrReplaceTempView(\"stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3292212-93d5-409c-81cc-41aace024926",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedRes = spark.sql(\"SELECT station, dayofweek,hour,longitude,latitude,criticality\\\n",
    "                       FROM criticals, stations\\\n",
    "                       WHERE criticals.station = stations.id\\\n",
    "                       ORDER BY criticality DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e67ff-e16f-4aa3-a121-4fd966b66af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedRes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a327c-84d6-4c13-a70a-ee37f229d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedRes.write.format(\"csv\").option(\"header\", True).save(outputPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
